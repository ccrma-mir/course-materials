{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MNjfrY7toSK"
      },
      "outputs": [],
      "source": [
        "# In this notebook we will get familiar with mirdata and PCA.\n",
        "\n",
        "# More specifically, we will work with the EGFxSet dataset,\n",
        "# which consists of Electric Guitar tones.\n",
        "\n",
        "# install mirdata on the colab shell\n",
        "!pip install # your code here\n",
        "\n",
        "# now import mirdata\n",
        "import # your code here"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now we can initialize egfxset and download it\n",
        "egfxset = mirdata.initialize(# your code here\n",
        "egfxset.download()"
      ],
      "metadata": {
        "id": "CiFKhQVxtqB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Many datasets in mirdata have a list with the name of all the\n",
        "# \"tracks\" (i.e. wav files). This list can be accessed with the\n",
        "# track_ids attribute\n",
        "\n",
        "# get the list with all tracks\n",
        "all_tracks = egfxset. # your code here\n",
        "\n",
        "# you can use the track class to access\n",
        "# each track's \"variables\", including the effects that it was played with\n",
        "\n",
        "# # Iterate over all track ids and save the unique effects and types\n",
        "unique_effects = []\n",
        "unique_effect_types = []\n",
        "for t in all_tracks:\n",
        "  unique_effects.append(egfxset.track(t) # your code here\n",
        "  unique_effect_types.append(egfxset.track(t) # your code here\n",
        "\n",
        "print(\"The unique effects (and types) are:\")\n",
        "print(set( # your code here\n",
        "print(set( # your code here"
      ],
      "metadata": {
        "id": "H-ZYUUnCUxaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now we will get a list with all the tracks for\n",
        "# two effects\n",
        "\n",
        "# define the effects you want to work with.\n",
        "# Use a pyton str with the effect name\n",
        "eff_1 = 'clean'\n",
        "eff_2 = 'tube screamer'\n",
        "\n",
        "# now iterate over these two effects\n",
        "# and save ALL the effect tracks in a list of strings\n",
        "eff_tracks = []\n",
        "for eff in [eff_1, eff_2]:\n",
        "  # your code here\n",
        "\n",
        "# now count how many tracks we have in total and\n",
        "# how many tracks belong to each effect\n",
        "N = len(eff_tracks)\n",
        "Ninst_1 =  # your code here\n",
        "Ninst_2 =  # your code here\n",
        "\n",
        "print(\"The total number of tracks is {}\".format(N))\n",
        "print(\"The number of trakcks for eff_1 is {}\".format(Ninst_1))\n",
        "print(\"The number of trakcks for eff_2 is {}\".format(Ninst_2))\n",
        "\n",
        "# now import numpy and librosa\n",
        "import numpy as np\n",
        "import librosa\n",
        "\n",
        "# now load all the audio files and append them\n",
        "# to a list of tracks called X\n",
        "# the files can be very big, so working with the\n",
        "# raw audio can be very inefficient\n",
        "# consider resampling to 8kHz, using only half\n",
        "# a second of audio, obtaining the fft magnitude (to discard\n",
        "# the negative frequencies), and converting to dB.\n",
        "# When done, cast X to be numpy array\n",
        "X = []\n",
        "fs8k = 8000\n",
        "for track in eff_tracks:\n",
        "  x,fs = egfxset.track(track).audio\n",
        "  # x = librosa.resample(x,orig_sr=fs,target_sr=fs8k)\n",
        "  X.append(librosa.amplitude_to_db(np.abs(np.fft.fft( # your code here\n",
        "X = np.array(X)\n",
        "\n",
        "print(\"The shape of X is\")\n",
        "print(X.shape)\n",
        "# Q: what's the meaning of the numbers in the shape of X?\n",
        "# A:\n",
        "\n",
        "# depending on the code you write, this can take a while to run\n",
        "\n",
        "print('The data is ready!')"
      ],
      "metadata": {
        "id": "hZvqBkhZt-BQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##################\n",
        "###    PCA     ###\n",
        "##################\n",
        "\n",
        "# Now we have a matrix X with datapoints and \"features\"\n",
        "# We can reduce the dimensionality of this data using PCA\n",
        "\n",
        "# 1. calculate mu, which has the mean of each feature\n",
        "# and subtract from X\n",
        "# Q: What type of object is mu? why do we need it? How do we use it?\n",
        "# A:\n",
        "mu = # your code here\n",
        "Xmu = # your code here\n",
        "\n",
        "# 2. now we calculate sigma, which is the standard deviation of each feature\n",
        "# and divide Xmu by it\n",
        "# Q: What type of object is sigma? why do we need it? How do we use it?\n",
        "# A:\n",
        "s = # your code here\n",
        "Xmus = # your code here\n",
        "\n",
        "\n",
        "# 3. now calculate the covariance matrix\n",
        "# Q: what are the dimensions of this matrix? why does it have that shape?\n",
        "# Q: what does this matrix tell us?\n",
        "# A:\n",
        "C = # your code here\n",
        "print(\"my covariance shape\")\n",
        "print(C.shape)\n",
        "\n",
        "# 4. you can find the Eigenvalues and Eigenvectors of C\n",
        "# Eigenvalues can have a complex type (Q: why? A: ).\n",
        "# Cast them to be real (Q: why can we do this here? A: )\n",
        "E, V = np.linalg.eig(C)\n",
        "E = np.real(E)\n",
        "\n",
        "# # 5. inspect how much of the data variance each\n",
        "# # eigenvalue-eigenvector pair explains. To do this\n",
        "# # you have to convert the eigenvalues to probabilities\n",
        "# # and multiply by 100 to convert to \"percent of variance explained\"\n",
        "# # round to two digits to make this easier to read\n",
        "\n",
        "perc_variance = # your code here to get a list with the percentage variance explained by each eigenvalue-eigenvector pair\n",
        "\n",
        "print(\"The percent of variance explained by each eigenvalue-eigenvector pair is: \")\n",
        "print(perc_variance)\n",
        "\n",
        "# Now we can reduce the dimensionality by defining a matrix W whose columns\n",
        "# are the two eigenvectors that correspond to the largest eigenvalues\n",
        "W = V[:,:2]\n",
        "\n",
        "# and proyecting the standardized data onto these eigenvectors\n",
        "X_reduced = np.dot( # your code here\n",
        "\n",
        "# X_reduced has your data, but with dimensionality reduced to the two components\n",
        "# that explain most of the variance in the data\n",
        "\n",
        "# Let's plot the results (you should not have to do anything here)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.scatter(X_reduced[Ninst_1:,0],X_reduced[Ninst_1:,1], label=eff_1)\n",
        "plt.scatter(X_reduced[:Ninst_1,0],X_reduced[:Ninst_1,1], label=eff_2)\n",
        "plt.legend()\n",
        "\n",
        "plt.xlabel('PCA 1')\n",
        "plt.ylabel('PCA 2')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DviYF-_vvwuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now learn how to do the same with the PCA object in sklearn\n",
        "# your do not have to do anything here if you did everything correctly in the previous cell\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# create the PCA instance with the number of components to be computed\n",
        "pca = PCA(n_components=2)\n",
        "\n",
        "# \"transform\" the data that you want to reduce to \"two components\"\n",
        "X_PCA = pca.fit_transform(Xmus)\n",
        "\n",
        "plt.scatter(X_PCA[Ninst_1:,0],X_PCA[Ninst_1:,1], label=inst_1)\n",
        "plt.scatter(X_PCA[:Ninst_1,0],X_PCA[:Ninst_1,1], label=inst_2)\n",
        "plt.legend()\n",
        "\n",
        "plt.xlabel('PCA 1')\n",
        "plt.ylabel('PCA 2')\n",
        "plt.show()\n",
        "\n",
        "# Q: Do the plots look the same? Why?\n",
        "# A:"
      ],
      "metadata": {
        "id": "GN812LVcx0CM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Here we have used the each signal's magnitude spectrum as the feature space\n",
        "# that we reduce using PCA.\n",
        "\n",
        "# Find the set of features that maximally separate the datapoints\n",
        "# belonging to two effects in EGFxSet. Be creative! Which\n",
        "# features best separate the two effects you have selected?\n",
        "\n",
        "# To compute PCA, you may use sklearn PCA or your \"by hand\" implementation.\n",
        "\n",
        "# Then do the same with the datapoints of three different effects of your choice\n",
        "\n",
        "# Add cells below to create the best plots you can with the datapoints of two and three\n",
        "# musical effects as maximally separated from each other as possible.\n",
        "\n",
        "# Q: Does your method work better for some effect combinations than others? why?\n",
        "# A:"
      ],
      "metadata": {
        "id": "8EmmdNjn3cdh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}